{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd587d6-795e-4999-ba72-10ccd8eee123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms.functional as TF\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6406a3f7-d566-4f01-a452-9517b3dfc987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_correct_study(patient_path):\n",
    "    for root, dirs, files in os.walk(patient_path):\n",
    "        #print(root, dirs, files)\n",
    "        dcm_files = [f for f in files if f.endswith(\".dcm\")]\n",
    "        if len(dcm_files) == 60:\n",
    "            return os.path.join(root)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527f9ced-d04a-4670-8bce-16ab21f71567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_patient_volume(patient_folder):\n",
    "    \"\"\"\n",
    "    Load the 60-slice DICOM volume for a patient.\n",
    "    Returns:\n",
    "        volume_np: (Z,H,W) float32 numpy array\n",
    "    \"\"\"\n",
    "    # Step 1: find the folder with exactly 60 .dcm files\n",
    "    subfolders = [os.path.join(patient_folder, f) for f in os.listdir(patient_folder) \n",
    "                  if os.path.isdir(os.path.join(patient_folder, f))]\n",
    "    \n",
    "    study_folder = load_correct_study(patient_folder)\n",
    "    if study_folder is None:\n",
    "        #print(f\"No 60-slice folder found in {patient_folder}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: read slices\n",
    "    dcm_files = sorted([os.path.join(study_folder,f) for f in os.listdir(study_folder) if f.lower().endswith('.dcm')])\n",
    "    slices = []\n",
    "    for f in dcm_files:\n",
    "        img = sitk.ReadImage(f)\n",
    "        arr = sitk.GetArrayFromImage(img)[0]  # (1,H,W) -> (H,W)\n",
    "        slices.append(arr.astype(np.float32))\n",
    "    \n",
    "    # Step 3: stack into volume\n",
    "    volume_np = np.stack(slices, axis=0)  # (Z,H,W)\n",
    "    \n",
    "    return volume_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca0c0b4-77c6-49cb-a3b5-a1104289e4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_consecutive_triplets(volume):\n",
    "    \"\"\"\n",
    "    Generate overlapping triplets: (slice[i], slice[i+2]) -> slice[i+1]\n",
    "    Returns lists of numpy arrays: pre_slices, post_slices, middle_slices\n",
    "    \"\"\"\n",
    "    pre_slices = []\n",
    "    post_slices = []\n",
    "    middle_slices = []\n",
    "    \n",
    "    for i in range(volume.shape[0]-2):\n",
    "        pre_slices.append(volume[i])\n",
    "        post_slices.append(volume[i+2])\n",
    "        middle_slices.append(volume[i+1])\n",
    "        \n",
    "    for i in range(volume.shape[0]-4):\n",
    "        pre_slices.append(volume[i])\n",
    "        post_slices.append(volume[i+4])\n",
    "        middle_slices.append(volume[i+2])\n",
    "        \n",
    "    return pre_slices, post_slices, middle_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c10c99a-d013-48fd-9762-e1673f9e5be6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multi-Image-Super-Resolution'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "parent_directory.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265b664e-99ee-4454-8022-9d5c682ac568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_progressive_triplets(volume):\n",
    "    \"\"\"\n",
    "    volume: (Z,H,W)\n",
    "    Returns: lists of pre_slices, post_slices, middle_slices\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    \n",
    "    def recursive_triplets(indices):\n",
    "        if len(indices) < 2:\n",
    "            return\n",
    "        start = indices[0]\n",
    "        end = indices[1]\n",
    "        if(start>end or end-start<=2):\n",
    "            return\n",
    "        mid = (start + end) // 2\n",
    "        if (mid != start and mid != end):\n",
    "            # add triplet: start & end -> mid\n",
    "            triplets.append((volume[start], volume[end], volume[mid]))\n",
    "            # recurse on left and right halves\n",
    "            recursive_triplets([start, mid])\n",
    "            recursive_triplets([mid, end])\n",
    "    \n",
    "    recursive_triplets([0, volume.shape[0]-1])\n",
    "    \n",
    "    # Unpack triplets\n",
    "    pre_slices = [t[0] for t in triplets]\n",
    "    post_slices = [t[1] for t in triplets]\n",
    "    middle_slices = [t[2] for t in triplets]\n",
    "    \n",
    "    return pre_slices, post_slices, middle_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b47a41e-1e21-4219-953d-d0b19ef28c36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = os.path.join(parent_directory, 'data','manifest-1694710246744','Prostate-MRI-US-Biopsy')\n",
    "#print(sorted(os.listdir(BASE_DIR)))\n",
    "patient_folders = sorted([f for f in os.listdir(BASE_DIR) if f.startswith(\"Prostate-MRI-US-Biopsy-\")])\n",
    "print(len(patient_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87178be9-c217-47f1-bc58-a093e274c5c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path, test_val_path = train_test_split(patient_folders, test_size = 0.3, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c53054-1810-411f-90ea-c4d75344a28e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f89d39-459b-4d79-9352-eae55cc67bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bafb683-1412-4d99-90d7-bef7d4868055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_path, test_path = train_test_split(test_val_path, test_size = 0.6, random_state = 42, shuffle = True)\n",
    "len(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78279366-74c0-4900-9bb1-c9222c4698b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa74e7b6-d51e-406e-9a57-e17c9aebce39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_no_slices_train = []\n",
    "count_no_slices_test = []\n",
    "count_no_slices_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca883871-630d-468d-9af7-e5fe3d8948ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(folders, split):\n",
    "    all_pre, all_post, all_middle = [], [], []\n",
    "    \n",
    "    for pid in folders:\n",
    "        patient_path = os.path.join(BASE_DIR, pid)\n",
    "        volume = load_patient_volume(patient_path)\n",
    "        if volume is None:\n",
    "            if(split == 'train'):\n",
    "                count_no_slices_train.append(patient_path)\n",
    "            elif(split == 'test'):\n",
    "                count_no_slices_test.append(patient_path)\n",
    "            else:\n",
    "                count_no_slices_val.append(patient_path)\n",
    "            continue\n",
    "        \n",
    "        pre, post, middle = generate_consecutive_triplets(volume)\n",
    "        all_pre.extend(pre)\n",
    "        all_post.extend(post)\n",
    "        all_middle.extend(middle)\n",
    "        \n",
    "    return all_pre, all_post, all_middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb9880d-1374-494e-bbb9-24688f14d07c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pre, train_post, train_middle = get_data(train_path, split = 'train')\n",
    "val_pre, val_post, val_middle = get_data(val_path, split = 'val')\n",
    "test_pre, test_post, test_middle = get_data(test_path, split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb0a0d87-7c68-456d-a13a-7e7b06b2355a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 22 9\n"
     ]
    }
   ],
   "source": [
    "print(len(count_no_slices_train), len(count_no_slices_test), len(count_no_slices_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de7c019c-e47e-48fb-bd00-4e79eff6bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletSliceDataset(Dataset):\n",
    "    def __init__(self, pre_slices, post_slices, middle_slices, transform=None):\n",
    "        assert len(pre_slices) == len(post_slices) == len(middle_slices)\n",
    "\n",
    "        self.pre = pre_slices\n",
    "        self.post = post_slices\n",
    "        self.mid = middle_slices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pre)\n",
    "\n",
    "    def normalize(self, x):\n",
    "        x = x.astype(np.float32)\n",
    "        mean = x.mean()\n",
    "        std = x.std()\n",
    "        if std < 1e-6: std = 1e-6\n",
    "        return (x - mean) / std\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pre  = self.normalize(self.pre[idx])\n",
    "        post = self.normalize(self.post[idx])\n",
    "        mid  = self.normalize(self.mid[idx])\n",
    "\n",
    "        # Convert to tensor CHW\n",
    "        pre  = torch.tensor(pre).unsqueeze(0)\n",
    "        post = torch.tensor(post).unsqueeze(0)\n",
    "        mid  = torch.tensor(mid).unsqueeze(0)\n",
    "\n",
    "        sample = {\"pre\": pre, \"post\": post, \"mid\": mid}\n",
    "\n",
    "        # Apply paired transforms\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return (sample[\"pre\"], sample[\"post\"]), sample[\"mid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "597251a5-46ca-4a38-8c76-2bb4a54889c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairedTransforms:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        pre, post, mid = sample[\"pre\"], sample[\"post\"], sample[\"mid\"]\n",
    "\n",
    "        # Random horizontal flip\n",
    "        if random.random() < 0.5:\n",
    "            pre = TF.hflip(pre)\n",
    "            post = TF.hflip(post)\n",
    "            mid = TF.hflip(mid)\n",
    "\n",
    "        # Random vertical flip\n",
    "        if random.random() < 0.5:\n",
    "            pre = TF.vflip(pre)\n",
    "            post = TF.vflip(post)\n",
    "            mid = TF.vflip(mid)\n",
    "\n",
    "        # Small rotation\n",
    "        angle = random.uniform(-5, 5)\n",
    "        pre = TF.rotate(pre, angle)\n",
    "        post = TF.rotate(post, angle)\n",
    "        mid = TF.rotate(mid, angle)\n",
    "\n",
    "        return {\"pre\": pre, \"post\": post, \"mid\": mid}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc770fb1-1eca-4efc-909f-ada6ff5acc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = PairedTransforms()\n",
    "\n",
    "dataset = TripletSliceDataset(\n",
    "    pre_slices, post_slices, middle_slices,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlmia-2",
   "language": "python",
   "name": "dlmia-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

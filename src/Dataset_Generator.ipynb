{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd587d6-795e-4999-ba72-10ccd8eee123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms.functional as TF\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6406a3f7-d566-4f01-a452-9517b3dfc987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_correct_study(patient_path):\n",
    "    for root, dirs, files in os.walk(patient_path):\n",
    "        #print(root, dirs, files)\n",
    "        dcm_files = [f for f in files if f.endswith(\".dcm\")]\n",
    "        if len(dcm_files) == 60:\n",
    "            return os.path.join(root)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527f9ced-d04a-4670-8bce-16ab21f71567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_patient_volume(patient_folder):\n",
    "    \"\"\"\n",
    "    Load the 60-slice DICOM volume for a patient.\n",
    "    Returns:\n",
    "        volume_np: (Z,H,W) float32 numpy array\n",
    "    \"\"\"\n",
    "    # Step 1: find the folder with exactly 60 .dcm files\n",
    "    subfolders = [os.path.join(patient_folder, f) for f in os.listdir(patient_folder) \n",
    "                  if os.path.isdir(os.path.join(patient_folder, f))]\n",
    "    \n",
    "    study_folder = load_correct_study(patient_folder)\n",
    "    if study_folder is None:\n",
    "        #print(f\"No 60-slice folder found in {patient_folder}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: read slices\n",
    "    dcm_files = sorted([os.path.join(study_folder,f) for f in os.listdir(study_folder) if f.lower().endswith('.dcm')])\n",
    "    slices = []\n",
    "    for f in dcm_files:\n",
    "        img = sitk.ReadImage(f)\n",
    "        arr = sitk.GetArrayFromImage(img)[0]  # (1,H,W) -> (H,W)\n",
    "        slices.append(arr.astype(np.float32))\n",
    "    \n",
    "    # Step 3: stack into volume\n",
    "    volume_np = np.stack(slices, axis=0)  # (Z,H,W)\n",
    "    \n",
    "    return volume_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca0c0b4-77c6-49cb-a3b5-a1104289e4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_consecutive_triplets(volume):\n",
    "    \"\"\"\n",
    "    Generate overlapping triplets: (slice[i], slice[i+2]) -> slice[i+1]\n",
    "    Returns lists of numpy arrays: pre_slices, post_slices, middle_slices\n",
    "    \"\"\"\n",
    "    pre_slices = []\n",
    "    post_slices = []\n",
    "    middle_slices = []\n",
    "    \n",
    "    for i in range(volume.shape[0]-2):\n",
    "        pre_slices.append(volume[i])\n",
    "        post_slices.append(volume[i+2])\n",
    "        middle_slices.append(volume[i+1])\n",
    "        \n",
    "    for i in range(volume.shape[0]-4):\n",
    "        pre_slices.append(volume[i])\n",
    "        post_slices.append(volume[i+4])\n",
    "        middle_slices.append(volume[i+2])\n",
    "        \n",
    "    return pre_slices, post_slices, middle_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c10c99a-d013-48fd-9762-e1673f9e5be6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multi-Image-Super-Resolution'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "parent_directory.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265b664e-99ee-4454-8022-9d5c682ac568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_progressive_triplets(volume):\n",
    "    \"\"\"\n",
    "    volume: (Z,H,W)\n",
    "    Returns: lists of pre_slices, post_slices, middle_slices\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    \n",
    "    def recursive_triplets(indices):\n",
    "        if len(indices) < 2:\n",
    "            return\n",
    "        start = indices[0]\n",
    "        end = indices[1]\n",
    "        if(start>end or end-start<=2):\n",
    "            return\n",
    "        mid = (start + end) // 2\n",
    "        if (mid != start and mid != end):\n",
    "            # add triplet: start & end -> mid\n",
    "            triplets.append((volume[start], volume[end], volume[mid]))\n",
    "            # recurse on left and right halves\n",
    "            recursive_triplets([start, mid])\n",
    "            recursive_triplets([mid, end])\n",
    "    \n",
    "    recursive_triplets([0, volume.shape[0]-1])\n",
    "    \n",
    "    # Unpack triplets\n",
    "    pre_slices = [t[0] for t in triplets]\n",
    "    post_slices = [t[1] for t in triplets]\n",
    "    middle_slices = [t[2] for t in triplets]\n",
    "    \n",
    "    return pre_slices, post_slices, middle_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b47a41e-1e21-4219-953d-d0b19ef28c36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = os.path.join(parent_directory, 'data','manifest-1694710246744','Prostate-MRI-US-Biopsy')\n",
    "#print(sorted(os.listdir(BASE_DIR)))\n",
    "patient_folders = sorted([f for f in os.listdir(BASE_DIR) if f.startswith(\"Prostate-MRI-US-Biopsy-\")])\n",
    "print(len(patient_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87178be9-c217-47f1-bc58-a093e274c5c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path, test_val_path = train_test_split(patient_folders, test_size = 0.3, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c53054-1810-411f-90ea-c4d75344a28e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f89d39-459b-4d79-9352-eae55cc67bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bafb683-1412-4d99-90d7-bef7d4868055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_path, test_path = train_test_split(test_val_path, test_size = 0.6, random_state = 42, shuffle = True)\n",
    "len(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78279366-74c0-4900-9bb1-c9222c4698b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa74e7b6-d51e-406e-9a57-e17c9aebce39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_no_slices_train = []\n",
    "count_no_slices_test = []\n",
    "count_no_slices_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca883871-630d-468d-9af7-e5fe3d8948ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(folders, split):\n",
    "    all_pre, all_post, all_middle = [], [], []\n",
    "    \n",
    "    for pid in folders:\n",
    "        patient_path = os.path.join(BASE_DIR, pid)\n",
    "        volume = load_patient_volume(patient_path)\n",
    "        if volume is None:\n",
    "            if(split == 'train'):\n",
    "                count_no_slices_train.append(patient_path)\n",
    "            elif(split == 'test'):\n",
    "                count_no_slices_test.append(patient_path)\n",
    "            else:\n",
    "                count_no_slices_val.append(patient_path)\n",
    "            continue\n",
    "        \n",
    "        pre, post, middle = generate_consecutive_triplets(volume)\n",
    "        all_pre.extend(pre)\n",
    "        all_post.extend(post)\n",
    "        all_middle.extend(middle)\n",
    "        \n",
    "    return all_pre, all_post, all_middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb9880d-1374-494e-bbb9-24688f14d07c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pre, train_post, train_middle = get_data(train_path, split = 'train')\n",
    "val_pre, val_post, val_middle = get_data(val_path, split = 'val')\n",
    "test_pre, test_post, test_middle = get_data(test_path, split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb0a0d87-7c68-456d-a13a-7e7b06b2355a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 22 9\n"
     ]
    }
   ],
   "source": [
    "print(len(count_no_slices_train), len(count_no_slices_test), len(count_no_slices_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de7c019c-e47e-48fb-bd00-4e79eff6bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletSliceDataset(Dataset):\n",
    "    def __init__(self, pre_slices, post_slices, middle_slices, transform=None):\n",
    "        assert len(pre_slices) == len(post_slices) == len(middle_slices)\n",
    "\n",
    "        self.pre = pre_slices\n",
    "        self.post = post_slices\n",
    "        self.mid = middle_slices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pre)\n",
    "\n",
    "    def normalize(self, x):\n",
    "        x = x.astype(np.float32)\n",
    "        mean = x.mean()\n",
    "        std = x.std()\n",
    "        if std < 1e-6: std = 1e-6\n",
    "        return (x - mean) / std\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pre  = self.normalize(self.pre[idx])\n",
    "        post = self.normalize(self.post[idx])\n",
    "        mid  = self.normalize(self.mid[idx])\n",
    "\n",
    "        # Convert to tensor CHW\n",
    "        pre  = torch.tensor(pre).unsqueeze(0)\n",
    "        post = torch.tensor(post).unsqueeze(0)\n",
    "        mid  = torch.tensor(mid).unsqueeze(0)\n",
    "\n",
    "        sample = {\"pre\": pre, \"post\": post, \"mid\": mid}\n",
    "\n",
    "        # Apply paired transforms\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return (sample[\"pre\"], sample[\"post\"]), sample[\"mid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "597251a5-46ca-4a38-8c76-2bb4a54889c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairedTransforms:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        pre, post, mid = sample[\"pre\"], sample[\"post\"], sample[\"mid\"]\n",
    "\n",
    "        # Random horizontal flip\n",
    "        if random.random() < 0.5:\n",
    "            pre = TF.hflip(pre)\n",
    "            post = TF.hflip(post)\n",
    "            mid = TF.hflip(mid)\n",
    "\n",
    "        # Random vertical flip\n",
    "        if random.random() < 0.5:\n",
    "            pre = TF.vflip(pre)\n",
    "            post = TF.vflip(post)\n",
    "            mid = TF.vflip(mid)\n",
    "\n",
    "        # Small rotation\n",
    "        angle = random.uniform(-5, 5)\n",
    "        pre = TF.rotate(pre, angle)\n",
    "        post = TF.rotate(post, angle)\n",
    "        mid = TF.rotate(mid, angle)\n",
    "\n",
    "        return {\"pre\": pre, \"post\": post, \"mid\": mid}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc770fb1-1eca-4efc-909f-ada6ff5acc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = PairedTransforms()\n",
    "\n",
    "dataset = TripletSliceDataset(\n",
    "    pre_slices, post_slices, middle_slices,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2cfaaf2-ea49-4b6d-b435-9b7d734b0676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ModelDataGenerator as MDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98846a69-ec51-404a-8961-328cbad02416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = MDL.build_dataloader(\n",
    "        split=\"train\",\n",
    "        batch_size=32,\n",
    "        augment=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf598eb0-a6f6-445b-80ad-28246edad367",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2284"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f83f591-4d2a-44bc-936d-53cbe6a66497",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmid\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/cruzcastrol/dthiyagarajan/.conda/envs/dlmia-2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/cruzcastrol/dthiyagarajan/.conda/envs/dlmia-2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1492\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1492\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1495\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/cruzcastrol/dthiyagarajan/.conda/envs/dlmia-2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1444\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1446\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/cruzcastrol/dthiyagarajan/.conda/envs/dlmia-2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1285\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1290\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/cruzcastrol/dthiyagarajan/.conda/envs/dlmia-2/lib/python3.12/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/cruzcastrol/dthiyagarajan/.conda/envs/dlmia-2/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(train_loader):\n",
    "    print(i)\n",
    "    (pre, post), mid = batch\n",
    "    if(pre.shape != post.shape or pre.shape != mid.shape):\n",
    "        print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b881d9c-6177-4f91-b66b-bd1558195233",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b169538-9046-4940-9165-cbf27cddebd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlmia-2",
   "language": "python",
   "name": "dlmia-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

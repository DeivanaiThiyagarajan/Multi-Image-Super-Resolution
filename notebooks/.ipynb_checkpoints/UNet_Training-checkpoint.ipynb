{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db1a2638",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "670c2351",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Device: cuda\n",
      "   GPU: NVIDIA L4\n",
      "   Memory: 23.67 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "# Check device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"‚úÖ Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe92402-b47f-4d1f-84ae-41425c9255a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup path to access custom modules\n",
    "root_directory = os.path.dirname(os.getcwd())\n",
    "sys.path.append(os.path.join(root_directory, 'src'))\n",
    "\n",
    "from ModelDataGenerator import build_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8cf36",
   "metadata": {},
   "source": [
    "# Model - UNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c25d2fe5-67c8-4691-9bbc-c22c88e67721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNetBlock(nn.Module):\n",
    "    \"\"\"Double convolution block with batch normalization\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNetBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a29234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet Architecture for medical image super-resolution\n",
    "    Input: (B, 2, H, W) - prior and posterior slices\n",
    "    Output: (B, 1, H, W) - predicted middle slice\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=2, out_channels=1, init_features=64):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        features = init_features\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = UNetBlock(in_channels, features)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.enc2 = UNetBlock(features, features * 2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.enc3 = UNetBlock(features * 2, features * 4)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.enc4 = UNetBlock(features * 4, features * 8)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = UNetBlock(features * 8, features * 16)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(features * 16, features * 8, kernel_size=2, stride=2)\n",
    "        self.dec4 = UNetBlock(features * 16, features * 8)\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(features * 8, features * 4, kernel_size=2, stride=2)\n",
    "        self.dec3 = UNetBlock(features * 8, features * 4)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(features * 4, features * 2, kernel_size=2, stride=2)\n",
    "        self.dec2 = UNetBlock(features * 4, features * 2)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(features * 2, features, kernel_size=2, stride=2)\n",
    "        self.dec1 = UNetBlock(features * 2, features)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.final_conv = nn.Conv2d(features, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder with skip connections\n",
    "        enc1 = self.enc1(x)\n",
    "        x = self.pool1(enc1)\n",
    "        \n",
    "        enc2 = self.enc2(x)\n",
    "        x = self.pool2(enc2)\n",
    "        \n",
    "        enc3 = self.enc3(x)\n",
    "        x = self.pool3(enc3)\n",
    "        \n",
    "        enc4 = self.enc4(x)\n",
    "        x = self.pool4(enc4)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        x = self.upconv4(x)\n",
    "        x = torch.cat([x, enc4], dim=1)\n",
    "        x = self.dec4(x)\n",
    "        \n",
    "        x = self.upconv3(x)\n",
    "        x = torch.cat([x, enc3], dim=1)\n",
    "        x = self.dec3(x)\n",
    "        \n",
    "        x = self.upconv2(x)\n",
    "        x = torch.cat([x, enc2], dim=1)\n",
    "        x = self.dec2(x)\n",
    "        \n",
    "        x = self.upconv1(x)\n",
    "        x = torch.cat([x, enc1], dim=1)\n",
    "        x = self.dec1(x)\n",
    "        \n",
    "        # Output\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd87d93-9ad7-4b09-8414-2e8f1787edd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully!\n",
      "üìä Total parameters: 31,042,945\n"
     ]
    }
   ],
   "source": [
    "# Test model initialization\n",
    "model = UNet(in_channels=2, out_channels=1, init_features=64)\n",
    "print(f\"‚úÖ Model created successfully!\")\n",
    "print(f\"üìä Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80dd5c",
   "metadata": {},
   "source": [
    "# Load Data from ModelDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582302d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader: 36537 batches\n",
      "Val loader: 6441 batches\n",
      "Test loader: 9120 batches\n",
      "\n",
      "üìä Sample batch shapes:\n",
      "Prior: torch.Size([2, 1, 256, 256])\n",
      "Posterior: torch.Size([2, 1, 256, 256])\n",
      "Target (middle): torch.Size([2, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 8  # Set to 0 for Windows, increase for Linux\n",
    "AUGMENT = True\n",
    "\n",
    "# Build dataloaders\n",
    "train_loader = build_dataloader(\n",
    "    split=\"train\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    augment=AUGMENT,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "val_loader = build_dataloader(\n",
    "    split=\"val\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    augment=False,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "test_loader = build_dataloader(\n",
    "    split=\"test\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    augment=False,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "print(f\"Train loader: {len(train_loader)} batches\")\n",
    "print(f\"Val loader: {len(val_loader)} batches\")\n",
    "print(f\"Test loader: {len(test_loader)} batches\")\n",
    "\n",
    "# Display sample batch shapes\n",
    "print(\"\\nüìä Sample batch shapes:\")\n",
    "for (pre, post), target in train_loader:\n",
    "    print(f\"Prior: {pre.shape}\")\n",
    "    print(f\"Posterior: {post.shape}\")\n",
    "    print(f\"Target (middle): {target.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6accb",
   "metadata": {},
   "source": [
    "# Training Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694934bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "Epochs: 10\n",
      "Learning rate: 0.0001\n",
      "Early stopping patience: 5\n",
      "Batch size: 2\n",
      "Augmentation: True\n",
      "Model save dir: ../models\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Configuration\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "MODEL_SAVE_DIR = Path('../models')\n",
    "MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Early stopping patience: {EARLY_STOPPING_PATIENCE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Augmentation: {AUGMENT}\")\n",
    "print(f\"Model save dir: {MODEL_SAVE_DIR}\")\n",
    "print()\n",
    "\n",
    "# Initialize model, optimizer, and loss\n",
    "model = UNet(in_channels=2, out_channels=1, init_features=64).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5396da01",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab8572f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 15389/36537 [18:56<22:07, 15.92it/s, loss=0.0277]   "
     ]
    }
   ],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for (pre, post), target in pbar:\n",
    "        # Stack prior and posterior as input (2 channels)\n",
    "        inputs = torch.cat([pre, post], dim=1).to(device)\n",
    "        targets = target.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
    "        for (pre, post), target in pbar:\n",
    "            # Stack prior and posterior as input (2 channels)\n",
    "            inputs = torch.cat([pre, post], dim=1).to(device)\n",
    "            targets = target.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "# Training variables\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"Starting training...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "    val_loss = validate(model, val_loader, criterion, DEVICE)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Print progress\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch:3d}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\", end=\"\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save best model\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'train_losses': train_losses,\n",
    "                'val_losses': val_losses\n",
    "            }\n",
    "            torch.save(checkpoint, MODEL_SAVE_DIR / 'unet_best.pt')\n",
    "            print(\"(Best)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\" (patience: {patience_counter}/{EARLY_STOPPING_PATIENCE})\")\n",
    "            \n",
    "            if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
    "                print(f\"\\nEarly stopping triggered after {epoch} epochs\\n\")\n",
    "                break\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Training completed!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78189ce",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc715dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion, device):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    predictions = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "        for (pre, post), target in pbar:\n",
    "            # Stack prior and posterior as input (2 channels)\n",
    "            inputs = torch.cat([pre, post], dim=1).to(device)\n",
    "            targets = target.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            predictions.append(outputs.cpu())\n",
    "            targets_list.append(targets.cpu())\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    return avg_loss, predictions, targets_list\n",
    "\n",
    "\n",
    "# Load best model\n",
    "best_model_path = MODEL_SAVE_DIR / 'unet_best.pt'\n",
    "if best_model_path.exists():\n",
    "    checkpoint = torch.load(best_model_path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"‚úÖ Best model loaded from epoch {checkpoint['epoch']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Best model not found, using current model\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nüß™ Evaluating on test set...\\n\")\n",
    "test_loss, predictions, targets_list = evaluate(model, test_loader, criterion, DEVICE)\n",
    "\n",
    "print(f\"‚úÖ Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1549df4",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b990ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss', linewidth=2, marker='o', markersize=3)\n",
    "plt.plot(val_losses, label='Validation Loss', linewidth=2, marker='s', markersize=3)\n",
    "plt.xlabel('Epoch', fontsize=11)\n",
    "plt.ylabel('Loss (MSE)', fontsize=11)\n",
    "plt.title('Training Progress', fontsize=12, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_losses, label='Validation Loss', linewidth=2, color='orange')\n",
    "plt.xlabel('Epoch', fontsize=11)\n",
    "plt.ylabel('Loss (MSE)', fontsize=11)\n",
    "plt.title('Validation Loss (Zoomed)', fontsize=12, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = MODEL_SAVE_DIR / 'training_curves.png'\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Training curves saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776a01f5",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Save Training Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a399512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "history = {\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'test_loss': test_loss,\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'epochs_trained': len(train_losses),\n",
    "    'config': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'early_stopping_patience': EARLY_STOPPING_PATIENCE,\n",
    "        'augmentation': AUGMENT,\n",
    "        'init_features': 64\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "log_path = MODEL_SAVE_DIR / 'training_history.json'\n",
    "with open(log_path, 'w') as f:\n",
    "    json.dump(history, f, indent=4)\n",
    "\n",
    "print(f\"üìù Training history saved to {log_path}\")\n",
    "print(f\"\\nüìä Training Summary:\")\n",
    "print(f\"   Epochs trained: {len(train_losses)}\")\n",
    "print(f\"   Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"   Final test loss: {test_loss:.4f}\")\n",
    "print(f\"   Final train loss: {train_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796fab4",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all predictions and targets\n",
    "all_predictions = torch.cat(predictions, dim=0)  # (N, 1, H, W)\n",
    "all_targets = torch.cat(targets_list, dim=0)      # (N, 1, H, W)\n",
    "\n",
    "# Visualize some predictions\n",
    "n_samples = 4\n",
    "fig, axes = plt.subplots(n_samples, 3, figsize=(12, 4*n_samples))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    pred = all_predictions[i, 0].numpy()\n",
    "    target = all_targets[i, 0].numpy()\n",
    "    diff = np.abs(pred - target)\n",
    "    \n",
    "    axes[i, 0].imshow(target, cmap='gray')\n",
    "    axes[i, 0].set_title(f'Target Slice {i+1}', fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(pred, cmap='gray')\n",
    "    axes[i, 1].set_title(f'Predicted Slice {i+1}', fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    im = axes[i, 2].imshow(diff, cmap='hot')\n",
    "    axes[i, 2].set_title(f'Difference {i+1}', fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "    plt.colorbar(im, ax=axes[i, 2], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "pred_path = MODEL_SAVE_DIR / 'predictions_visualization.png'\n",
    "plt.savefig(pred_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üñºÔ∏è  Predictions visualization saved to {pred_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988ba56",
   "metadata": {},
   "source": [
    "## üîü Model Save Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a66b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÇ Models saved to: {MODEL_SAVE_DIR}\")\n",
    "print(f\"\\nüìã Files created:\")\n",
    "\n",
    "for file in sorted(MODEL_SAVE_DIR.glob('*')):\n",
    "    size = file.stat().st_size / (1024*1024)  # MB\n",
    "    print(f\"   ‚úì {file.name:40s} ({size:6.2f} MB)\")\n",
    "\n",
    "print(f\"\\nüìä Key Results:\")\n",
    "print(f\"   Best Validation Loss: {best_val_loss:.4f}\")\n",
    "print(f\"   Final Test Loss: {test_loss:.4f}\")\n",
    "print(f\"   Total Epochs: {len(train_losses)}\")\n",
    "print(f\"   Improvement: {(train_losses[0] - test_loss) / train_losses[0] * 100:.2f}%\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlmia-2",
   "language": "python",
   "name": "dlmia-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

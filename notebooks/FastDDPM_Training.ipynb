{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380e5471",
   "metadata": {},
   "source": [
    "# Fast-DDPM: Fast Denoising Diffusion Probabilistic Models for Medical Image Super-Resolution\n",
    "\n",
    "## What is Fast-DDPM?\n",
    "\n",
    "**Traditional DDPM (Denoising Diffusion Probabilistic Models):**\n",
    "- Forward process: Add Gaussian noise to images over 1000 timesteps\n",
    "- Reverse process: Learn to denoise images step-by-step\n",
    "- Problem: Very slow - requires 1000 denoising steps at inference\n",
    "\n",
    "**Fast-DDPM (Our Approach):**\n",
    "- **Key Innovation:** Use only 10 timesteps instead of 1000\n",
    "- **How:** Skip intermediate steps using accelerated sampling schedule (uniform or non-uniform)\n",
    "- **Result:** \n",
    "  - Training time: **0.2x of DDPM** (5x faster)\n",
    "  - Sampling time: **0.01x of DDPM** (100x faster!)\n",
    "  - Quality: Same or better than DDPM\n",
    "\n",
    "## How It Works\n",
    "\n",
    "```\n",
    "Standard DDPM (1000 steps):\n",
    "t=0 → t=1 → t=2 → ... → t=999 → t=1000 (all steps)\n",
    "\n",
    "Fast-DDPM (10 steps):\n",
    "t=0 → t=100 → t=200 → ... → t=900 → t=1000 (skip intermediate steps)\n",
    "      ↓\n",
    "      Jump to key timesteps only\n",
    "```\n",
    "\n",
    "## For Your Medical Image Task\n",
    "\n",
    "- **Input:** 3 consecutive slices [i, i+1, i+2]\n",
    "- **Task:** Generate the middle slice (i+1) only\n",
    "- **Advantage:** \n",
    "  - Simpler, faster training\n",
    "  - Middle slice prediction (most stable)\n",
    "  - Probabilistic approach with uncertainty\n",
    "  - Can ensemble multiple predictions for better quality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5220adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690fe07e",
   "metadata": {},
   "source": [
    "## Noise Schedule: Pre-compute 1000 timesteps, use only 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6145954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMScheduler:\n",
    "    def __init__(self, num_timesteps=1000, num_inference_steps=10, scheduler_type='uniform'):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.num_inference_steps = num_inference_steps\n",
    "        \n",
    "        betas = np.linspace(0.0001, 0.02, num_timesteps)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas)\n",
    "        \n",
    "        self.betas = torch.from_numpy(betas).float()\n",
    "        self.alphas = torch.from_numpy(alphas).float()\n",
    "        self.alphas_cumprod = torch.from_numpy(alphas_cumprod).float()\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - self.alphas_cumprod)\n",
    "        \n",
    "        if scheduler_type == 'uniform':\n",
    "            self.timesteps = np.linspace(0, num_timesteps - 1, num_inference_steps).astype(int)\n",
    "        else:\n",
    "            self.timesteps = np.ceil(np.linspace(0, num_timesteps - 1, num_inference_steps) ** 1.1).astype(int)\n",
    "        \n",
    "        self.timesteps = torch.from_numpy(self.timesteps).long()\n",
    "    \n",
    "    def add_noise(self, x0, t, noise):\n",
    "        sqrt_alpha = self.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        return sqrt_alpha * x0 + sqrt_one_minus_alpha * noise\n",
    "\n",
    "scheduler = DDPMScheduler(num_timesteps=1000, num_inference_steps=10, scheduler_type='uniform')\n",
    "print(f\"Timesteps: {scheduler.timesteps.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e61a444",
   "metadata": {},
   "source": [
    "## UNet with Time Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee5498",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, t):\n",
    "        t = t.float().unsqueeze(-1) / 1000.0\n",
    "        return self.fc(t)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.GroupNorm(32, in_ch)\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(32, out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        self.time_fc = nn.Linear(time_dim, out_ch)\n",
    "        self.skip = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, t_emb):\n",
    "        h = self.norm1(x)\n",
    "        h = F.silu(h)\n",
    "        h = self.conv1(h)\n",
    "        h = h + self.time_fc(t_emb)[:, :, None, None]\n",
    "        h = self.norm2(h)\n",
    "        h = F.silu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(h)\n",
    "        return h + self.skip(x)\n",
    "\n",
    "class FastDDPMUNet(nn.Module):\n",
    "    def __init__(self, in_ch=2, out_ch=1, base_ch=64, time_dim=128):\n",
    "        super().__init__()\n",
    "        self.time_emb = TimeEmbedding(time_dim)\n",
    "        self.init_conv = nn.Conv2d(in_ch, base_ch, 3, padding=1)\n",
    "        \n",
    "        self.enc1 = ResBlock(base_ch, base_ch * 2, time_dim)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ResBlock(base_ch * 2, base_ch * 4, time_dim)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ResBlock(base_ch * 4, base_ch * 8, time_dim)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.bottleneck = ResBlock(base_ch * 8, base_ch * 8, time_dim)\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(base_ch * 8, base_ch * 4, 2, 2)\n",
    "        self.dec3 = ResBlock(base_ch * 8, base_ch * 4, time_dim)\n",
    "        self.upconv2 = nn.ConvTranspose2d(base_ch * 4, base_ch * 2, 2, 2)\n",
    "        self.dec2 = ResBlock(base_ch * 4, base_ch * 2, time_dim)\n",
    "        self.upconv1 = nn.ConvTranspose2d(base_ch * 2, base_ch, 2, 2)\n",
    "        self.dec1 = ResBlock(base_ch * 2, base_ch, time_dim)\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.GroupNorm(32, base_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, out_ch, 3, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        t_emb = self.time_emb(t)\n",
    "        \n",
    "        h = self.init_conv(x)\n",
    "        e1 = self.enc1(h, t_emb)\n",
    "        h = self.pool1(e1)\n",
    "        e2 = self.enc2(h, t_emb)\n",
    "        h = self.pool2(e2)\n",
    "        e3 = self.enc3(h, t_emb)\n",
    "        h = self.pool3(e3)\n",
    "        \n",
    "        h = self.bottleneck(h, t_emb)\n",
    "        \n",
    "        h = self.upconv3(h)\n",
    "        h = torch.cat([h, e3], dim=1)\n",
    "        h = self.dec3(h, t_emb)\n",
    "        h = self.upconv2(h)\n",
    "        h = torch.cat([h, e2], dim=1)\n",
    "        h = self.dec2(h, t_emb)\n",
    "        h = self.upconv1(h)\n",
    "        h = torch.cat([h, e1], dim=1)\n",
    "        h = self.dec1(h, t_emb)\n",
    "        \n",
    "        return self.final(h)\n",
    "\n",
    "model = FastDDPMUNet(in_ch=2, out_ch=1)\n",
    "print(f\"Model params: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20b0baf",
   "metadata": {},
   "source": [
    "## Data Loading from ModelDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22977bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')\n",
    "from ModelDataGenerator import build_dataloader\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "CHECKPOINT_DIR = '../models'\n",
    "\n",
    "train_loader = build_dataloader(split='train', batch_size=BATCH_SIZE, augment=True, num_workers=NUM_WORKERS)\n",
    "val_loader = build_dataloader(split='val', batch_size=BATCH_SIZE, augment=False, num_workers=NUM_WORKERS)\n",
    "test_loader = build_dataloader(split='test', batch_size=BATCH_SIZE, augment=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f\"Train: {len(train_loader)} | Val: {len(val_loader)} | Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bbf745",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91699dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastDDPMUNet(in_ch=2, out_ch=1).to(DEVICE)\n",
    "scheduler_device = DDPMScheduler(num_timesteps=1000, num_inference_steps=10, scheduler_type='uniform')\n",
    "for key in ['betas', 'alphas', 'alphas_cumprod', 'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod']:\n",
    "    setattr(scheduler_device, key, getattr(scheduler_device, key).to(DEVICE))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    for (pre, post), target in tqdm(train_loader, leave=False):\n",
    "        pre, post, target = pre.to(DEVICE), post.to(DEVICE), target.to(DEVICE)\n",
    "        x_input = torch.cat([pre, post], dim=1)\n",
    "        \n",
    "        batch_size = x_input.shape[0]\n",
    "        t_idx = torch.randint(0, len(scheduler_device.timesteps), (batch_size,))\n",
    "        t = scheduler_device.timesteps[t_idx].to(DEVICE)\n",
    "        \n",
    "        noise = torch.randn_like(target)\n",
    "        x_noisy = scheduler_device.add_noise(target, t, noise)\n",
    "        \n",
    "        pred_noise = model(x_input, t)\n",
    "        loss = criterion(pred_noise, noise)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "    \n",
    "    return loss_sum / len(train_loader)\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for (pre, post), target in tqdm(val_loader, leave=False):\n",
    "            pre, post, target = pre.to(DEVICE), post.to(DEVICE), target.to(DEVICE)\n",
    "            x_input = torch.cat([pre, post], dim=1)\n",
    "            \n",
    "            batch_size = x_input.shape[0]\n",
    "            t_idx = torch.randint(0, len(scheduler_device.timesteps), (batch_size,))\n",
    "            t = scheduler_device.timesteps[t_idx].to(DEVICE)\n",
    "            \n",
    "            noise = torch.randn_like(target)\n",
    "            x_noisy = scheduler_device.add_noise(target, t, noise)\n",
    "            \n",
    "            pred_noise = model(x_input, t)\n",
    "            loss = criterion(pred_noise, noise)\n",
    "            \n",
    "            loss_sum += loss.item()\n",
    "    \n",
    "    return loss_sum / len(val_loader)\n",
    "\n",
    "best_loss = float('inf')\n",
    "history = {'epoch': [], 'train_loss': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = train_epoch()\n",
    "    val_loss = validate()\n",
    "    \n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d}/{EPOCHS} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\", end=\"\")\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'{CHECKPOINT_DIR}/fastddpm_best.pt')\n",
    "        print(\" ✅\")\n",
    "    else:\n",
    "        print()\n",
    "\n",
    "with open(f'{CHECKPOINT_DIR}/fastddpm_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"\\nBest Val Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54269a5b",
   "metadata": {},
   "source": [
    "## Sampling (Reverse Diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c3403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(pre, post, num_samples=1):\n",
    "    model.eval()\n",
    "    batch_size = pre.shape[0]\n",
    "    \n",
    "    generated = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        x_t = torch.randn(batch_size, 1, pre.shape[2], pre.shape[3]).to(DEVICE)\n",
    "        \n",
    "        for step_idx, t in enumerate(reversed(scheduler_device.timesteps)):\n",
    "            t = t.to(DEVICE)\n",
    "            x_input = torch.cat([pre.to(DEVICE), post.to(DEVICE)], dim=1)\n",
    "            \n",
    "            pred_noise = model(x_input, t.unsqueeze(0).expand(batch_size))\n",
    "            \n",
    "            alpha = scheduler_device.alphas_cumprod[t]\n",
    "            alpha_prev = scheduler_device.alphas_cumprod[scheduler_device.timesteps[max(0, step_idx - 1)]]\n",
    "            \n",
    "            posterior_var = (1 - alpha_prev) / (1 - alpha) * (1 - alpha / alpha_prev)\n",
    "            posterior_var = torch.clamp(posterior_var, min=1e-20)\n",
    "            \n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x_t)\n",
    "            else:\n",
    "                noise = torch.zeros_like(x_t)\n",
    "            \n",
    "            x_t = (1 / torch.sqrt(alpha)) * (x_t - (1 - alpha) / torch.sqrt(1 - alpha) * pred_noise) + torch.sqrt(posterior_var) * noise\n",
    "        \n",
    "        generated.append(x_t.cpu())\n",
    "    \n",
    "    return torch.stack(generated, dim=1)\n",
    "\n",
    "print(\"Sampling ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf4632",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab32079",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{CHECKPOINT_DIR}/fastddpm_best.pt'))\n",
    "\n",
    "ssim_scores = []\n",
    "psnr_scores = []\n",
    "\n",
    "for (pre, post), target in tqdm(test_loader):\n",
    "    generated = sample(pre, post, num_samples=3)\n",
    "    pred = generated.mean(dim=1).squeeze().cpu().numpy()\n",
    "    gt = target.squeeze().cpu().numpy()\n",
    "    \n",
    "    for i in range(len(gt)):\n",
    "        gt_norm = (gt[i] - gt[i].min()) / (gt[i].max() - gt[i].min() + 1e-8)\n",
    "        pred_norm = (pred[i] - pred[i].min()) / (pred[i].max() - pred[i].min() + 1e-8)\n",
    "        \n",
    "        ssim_scores.append(ssim(gt_norm, pred_norm, data_range=1.0))\n",
    "        psnr_scores.append(psnr(gt_norm, pred_norm, data_range=1.0))\n",
    "\n",
    "print(f\"\\nSSIM: {np.mean(ssim_scores):.4f} ± {np.std(ssim_scores):.4f}\")\n",
    "print(f\"PSNR: {np.mean(psnr_scores):.2f} ± {np.std(psnr_scores):.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e235bf6",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf60987",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['epoch'], history['train_loss'], 'o-', label='Train')\n",
    "plt.plot(history['epoch'], history['val_loss'], 's-', label='Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Fast-DDPM Training')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{CHECKPOINT_DIR}/fastddpm_training.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2339a9e2",
   "metadata": {},
   "source": [
    "## Noise Schedule: Accelerated Timestep Selection\n",
    "\n",
    "Pre-compute all 1000 noise levels, but sample only 10 timesteps during training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6717c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMScheduler:\n",
    "    def __init__(self, num_timesteps=1000, num_inference_steps=10, scheduler_type='uniform'):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.num_inference_steps = num_inference_steps\n",
    "        \n",
    "        # Pre-compute alphas for all 1000 timesteps\n",
    "        betas = np.linspace(0.0001, 0.02, num_timesteps)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas)\n",
    "        \n",
    "        self.register_buffer('betas', torch.from_numpy(betas).float())\n",
    "        self.register_buffer('alphas', torch.from_numpy(alphas).float())\n",
    "        self.register_buffer('alphas_cumprod', torch.from_numpy(alphas_cumprod).float())\n",
    "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(torch.from_numpy(alphas_cumprod)).float())\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1 - torch.from_numpy(alphas_cumprod)).float())\n",
    "        \n",
    "        # Select timesteps: 10 instead of 1000\n",
    "        if scheduler_type == 'uniform':\n",
    "            self.timesteps = np.linspace(0, num_timesteps - 1, num_inference_steps).astype(int)\n",
    "        else:  # non-uniform\n",
    "            self.timesteps = np.ceil(np.linspace(0, num_timesteps - 1, num_inference_steps) ** 1.1).astype(int)\n",
    "        \n",
    "        self.timesteps = torch.from_numpy(self.timesteps).long()\n",
    "    \n",
    "    def register_buffer(self, name, tensor):\n",
    "        setattr(self, name, tensor)\n",
    "    \n",
    "    def add_noise(self, x0, t, noise):\n",
    "        sqrt_alpha = self.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        return sqrt_alpha * x0 + sqrt_one_minus_alpha * noise\n",
    "\n",
    "scheduler = DDPMScheduler(num_timesteps=1000, num_inference_steps=10, scheduler_type='uniform')\n",
    "print(f\"Selected timesteps: {scheduler.timesteps.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a891efc6",
   "metadata": {},
   "source": [
    "## UNet with Time Embedding\n",
    "\n",
    "Lightweight UNet for conditioning on timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, t):\n",
    "        t = t.float().unsqueeze(-1) / 1000.0\n",
    "        return self.fc(t)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.GroupNorm(32, in_ch)\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(32, out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        self.time_fc = nn.Linear(time_dim, out_ch)\n",
    "        self.skip = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, t_emb):\n",
    "        h = self.norm1(x)\n",
    "        h = F.silu(h)\n",
    "        h = self.conv1(h)\n",
    "        h = h + self.time_fc(t_emb)[:, :, None, None]\n",
    "        h = self.norm2(h)\n",
    "        h = F.silu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(h)\n",
    "        return h + self.skip(x)\n",
    "\n",
    "class FastDDPMUNet(nn.Module):\n",
    "    def __init__(self, in_ch=2, out_ch=1, base_ch=64, time_dim=128):\n",
    "        super().__init__()\n",
    "        self.time_emb = TimeEmbedding(time_dim)\n",
    "        self.init_conv = nn.Conv2d(in_ch, base_ch, 3, padding=1)\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = ResBlock(base_ch, base_ch * 2, time_dim)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ResBlock(base_ch * 2, base_ch * 4, time_dim)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ResBlock(base_ch * 4, base_ch * 8, time_dim)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResBlock(base_ch * 8, base_ch * 8, time_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv3 = nn.ConvTranspose2d(base_ch * 8, base_ch * 4, 2, 2)\n",
    "        self.dec3 = ResBlock(base_ch * 8, base_ch * 4, time_dim)\n",
    "        self.upconv2 = nn.ConvTranspose2d(base_ch * 4, base_ch * 2, 2, 2)\n",
    "        self.dec2 = ResBlock(base_ch * 4, base_ch * 2, time_dim)\n",
    "        self.upconv1 = nn.ConvTranspose2d(base_ch * 2, base_ch, 2, 2)\n",
    "        self.dec1 = ResBlock(base_ch * 2, base_ch, time_dim)\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.GroupNorm(32, base_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, out_ch, 3, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        t_emb = self.time_emb(t)\n",
    "        \n",
    "        h = self.init_conv(x)\n",
    "        e1 = self.enc1(h, t_emb)\n",
    "        h = self.pool1(e1)\n",
    "        e2 = self.enc2(h, t_emb)\n",
    "        h = self.pool2(e2)\n",
    "        e3 = self.enc3(h, t_emb)\n",
    "        h = self.pool3(e3)\n",
    "        \n",
    "        h = self.bottleneck(h, t_emb)\n",
    "        \n",
    "        h = self.upconv3(h)\n",
    "        h = torch.cat([h, e3], dim=1)\n",
    "        h = self.dec3(h, t_emb)\n",
    "        h = self.upconv2(h)\n",
    "        h = torch.cat([h, e2], dim=1)\n",
    "        h = self.dec2(h, t_emb)\n",
    "        h = self.upconv1(h)\n",
    "        h = torch.cat([h, e1], dim=1)\n",
    "        h = self.dec1(h, t_emb)\n",
    "        \n",
    "        return self.final(h)\n",
    "\n",
    "model = FastDDPMUNet(in_ch=2, out_ch=1)\n",
    "print(f\"Model params: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bc4dd8",
   "metadata": {},
   "source": [
    "## Configuration & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792d23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')\n",
    "from ModelDataGenerator import build_dataloader\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "CHECKPOINT_DIR = '../models'\n",
    "\n",
    "train_loader = build_dataloader(split='train', batch_size=BATCH_SIZE, augment=True, num_workers=NUM_WORKERS)\n",
    "val_loader = build_dataloader(split='val', batch_size=BATCH_SIZE, augment=False, num_workers=NUM_WORKERS)\n",
    "test_loader = build_dataloader(split='test', batch_size=BATCH_SIZE, augment=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f\"Train: {len(train_loader)} | Val: {len(val_loader)} | Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d29b19",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastDDPMUNet(in_ch=2, out_ch=1).to(DEVICE)\n",
    "scheduler_device = DDPMScheduler(num_timesteps=1000, num_inference_steps=10, scheduler_type='uniform')\n",
    "for key in ['betas', 'alphas', 'alphas_cumprod', 'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod']:\n",
    "    setattr(scheduler_device, key, getattr(scheduler_device, key).to(DEVICE))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    for (pre, post), target in tqdm(train_loader, leave=False):\n",
    "        pre, post, target = pre.to(DEVICE), post.to(DEVICE), target.to(DEVICE)\n",
    "        x_input = torch.cat([pre, post], dim=1)  # (B, 2, H, W)\n",
    "        \n",
    "        batch_size = x_input.shape[0]\n",
    "        t_idx = torch.randint(0, len(scheduler_device.timesteps), (batch_size,))\n",
    "        t = scheduler_device.timesteps[t_idx].to(DEVICE)\n",
    "        \n",
    "        noise = torch.randn_like(target)\n",
    "        x_noisy = scheduler_device.add_noise(target, t, noise)\n",
    "        \n",
    "        pred_noise = model(x_input, t)\n",
    "        loss = criterion(pred_noise, noise)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "    \n",
    "    return loss_sum / len(train_loader)\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for (pre, post), target in tqdm(val_loader, leave=False):\n",
    "            pre, post, target = pre.to(DEVICE), post.to(DEVICE), target.to(DEVICE)\n",
    "            x_input = torch.cat([pre, post], dim=1)\n",
    "            \n",
    "            batch_size = x_input.shape[0]\n",
    "            t_idx = torch.randint(0, len(scheduler_device.timesteps), (batch_size,))\n",
    "            t = scheduler_device.timesteps[t_idx].to(DEVICE)\n",
    "            \n",
    "            noise = torch.randn_like(target)\n",
    "            x_noisy = scheduler_device.add_noise(target, t, noise)\n",
    "            \n",
    "            pred_noise = model(x_input, t)\n",
    "            loss = criterion(pred_noise, noise)\n",
    "            \n",
    "            loss_sum += loss.item()\n",
    "    \n",
    "    return loss_sum / len(val_loader)\n",
    "\n",
    "best_loss = float('inf')\n",
    "history = {'epoch': [], 'train_loss': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = train_epoch()\n",
    "    val_loss = validate()\n",
    "    \n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d}/{EPOCHS} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\", end=\"\")\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'{CHECKPOINT_DIR}/fastddpm_best.pt')\n",
    "        print(\" ✅\")\n",
    "    else:\n",
    "        print()\n",
    "\n",
    "with open(f'{CHECKPOINT_DIR}/fastddpm_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"\\nBest Val Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ff6633",
   "metadata": {},
   "source": [
    "## Sampling (Fast-DDPM Reverse Process)\n",
    "\n",
    "Generate middle slice from (pre, post) using only 10 denoising steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(pre, post, num_samples=1):\n",
    "    model.eval()\n",
    "    batch_size = pre.shape[0]\n",
    "    \n",
    "    generated = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        x_t = torch.randn(batch_size, 1, pre.shape[2], pre.shape[3]).to(DEVICE)\n",
    "        \n",
    "        for step_idx, t in enumerate(reversed(scheduler_device.timesteps)):\n",
    "            t = t.to(DEVICE)\n",
    "            x_input = torch.cat([pre.to(DEVICE), post.to(DEVICE)], dim=1)\n",
    "            \n",
    "            pred_noise = model(x_input, t.unsqueeze(0).expand(batch_size))\n",
    "            \n",
    "            alpha = scheduler_device.alphas_cumprod[t]\n",
    "            alpha_prev = scheduler_device.alphas_cumprod[scheduler_device.timesteps[max(0, step_idx - 1)]]\n",
    "            \n",
    "            posterior_var = (1 - alpha_prev) / (1 - alpha) * (1 - alpha / alpha_prev)\n",
    "            posterior_var = torch.clamp(posterior_var, min=1e-20)\n",
    "            \n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x_t)\n",
    "            else:\n",
    "                noise = torch.zeros_like(x_t)\n",
    "            \n",
    "            x_t = (1 / torch.sqrt(alpha)) * (x_t - (1 - alpha) / torch.sqrt(1 - alpha) * pred_noise) + torch.sqrt(posterior_var) * noise\n",
    "        \n",
    "        generated.append(x_t.cpu())\n",
    "    \n",
    "    return torch.stack(generated, dim=1)  # (B, num_samples, 1, H, W)\n",
    "\n",
    "print(\"Sampling function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f31aa9",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56415339",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{CHECKPOINT_DIR}/fastddpm_best.pt'))\n",
    "\n",
    "ssim_scores = []\n",
    "psnr_scores = []\n",
    "\n",
    "for (pre, post), target in tqdm(test_loader):\n",
    "    generated = sample(pre, post, num_samples=3)\n",
    "    pred = generated.mean(dim=1).squeeze().cpu().numpy()\n",
    "    gt = target.squeeze().cpu().numpy()\n",
    "    \n",
    "    for i in range(len(gt)):\n",
    "        gt_norm = (gt[i] - gt[i].min()) / (gt[i].max() - gt[i].min() + 1e-8)\n",
    "        pred_norm = (pred[i] - pred[i].min()) / (pred[i].max() - pred[i].min() + 1e-8)\n",
    "        \n",
    "        ssim_scores.append(ssim(gt_norm, pred_norm, data_range=1.0))\n",
    "        psnr_scores.append(psnr(gt_norm, pred_norm, data_range=1.0))\n",
    "\n",
    "print(f\"\\nSSIM: {np.mean(ssim_scores):.4f} ± {np.std(ssim_scores):.4f}\")\n",
    "print(f\"PSNR: {np.mean(psnr_scores):.2f} ± {np.std(psnr_scores):.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a307f4",
   "metadata": {},
   "source": [
    "## Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff98442",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['epoch'], history['train_loss'], 'o-', label='Train')\n",
    "plt.plot(history['epoch'], history['val_loss'], 's-', label='Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Fast-DDPM Training')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{CHECKPOINT_DIR}/fastddpm_training.png', dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
